{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential removal of links and resiliency testing\n",
    "\n",
    "- Disruption of a network by removal of links, based on:\n",
    "    + Sum of betweeness centrality of from and to nodes\n",
    "    + Link length\n",
    "    + Volume of commodity flow\n",
    "- Calculation of performance in terms of cost and unmet demand by re-running disrupted network on FOT\n",
    "- Plot link removal along x-axis and performance on y-axis, comparing networks of differing evenness. Dynamic report generated in an Rmarkdown automatically from this Notebook.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- Working in a Python 3.x environment for this notebook\n",
    "    + Refer to the README in this repository for instructions on setup of all dependencies with `conda`\n",
    "- Python 2.7 installed as part of ArcGIS\n",
    "- 64 bit background geoprocessing enabled\n",
    "- Access to ArcGIS license server if necessary \n",
    "\n",
    "*Reference*\n",
    "\n",
    "- [NetworkX Documentation](https://networkx.github.io/documentation/stable/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy \n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import resiliency_disruptions\n",
    "\n",
    "# Uses Quick Start 7 as an example. Modify `scen_name` and `scen_path` for your scenario.\n",
    "scen_name = 'qs7_rmp_proc_dest_multi_inputs'\n",
    "\n",
    "scen_path = os.path.join(\"C:\\\\FTOT\\\\scenarios\\\\quick_start\\\\\", scen_name)\n",
    "\n",
    "shp_path = os.path.join(scen_path, 'temp_networkx_shp_files')\n",
    "\n",
    "picklename = scen_name + 'BetweenessG.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(picklename):\n",
    "    file = open(picklename, 'rb')\n",
    "    betweenness_dict_road = pickle.load(file)\n",
    "    G_road = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using betweeness centrality calculation using networkX\n",
    "if not os.path.exists(picklename):\n",
    "    G_road = nx.read_shp(os.path.join(shp_path, 'road.shp'), simplify=True)\n",
    "    G_road = nx.convert_node_labels_to_integers(G_road, first_label=0, ordering='default', label_attribute=\"xy_coord_label\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Betweeness Centrality calculations. This might take more than 20 minutes.\n",
      "Completed Betweeness Centrality calculations.\n"
     ]
    }
   ],
   "source": [
    "# Run betweenness centrality on the NetworkX graph\n",
    "# Note: This step might take 20+ minutes\n",
    "# Run if pickle not available\n",
    "if not os.path.exists(picklename):\n",
    "    print('Running Betweeness Centrality calculations. This might take more than 20 minutes.')\n",
    "    betweenness_dict_road = nx.betweenness_centrality(G_road, normalized=False, weight='MILES')\n",
    "    print('Completed Betweeness Centrality calculations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with pickle\n",
    "# On load, need to know that there are two objects in this pickle, the betweeness centrality dict and the network G\n",
    "if not os.path.exists(picklename):\n",
    "    with open(picklename, 'wb') as handle:\n",
    "        pickle.dump(betweenness_dict_road, handle)\n",
    "        pickle.dump(G_road, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Betweeness Centrality calculations to edges \n",
    "\n",
    "- Sum BC for each node of a link\n",
    "- Create data frame for repeated link removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\scenarios\\quick_start\\qs7_rmp_proc_dest_multi_inputs\n"
     ]
    }
   ],
   "source": [
    "# Read in FTOT data\n",
    "print(scen_path)\n",
    "db_name = 'main.db'\n",
    "\n",
    "db_path = 'sqlite:///' + os.path.join(scen_path, db_name)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_path)\n",
    "\n",
    "table_name = 'networkx_edges'\n",
    "nx_edges = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'networkx_nodes'\n",
    "nx_nodes = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'optimal_variables'\n",
    "optimal_vars = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_road_orig_label = nx.read_shp(os.path.join(shp_path, 'road.shp'), simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_orig_label_nodes = list(G_road_orig_label.nodes) # these values are the shape_x and shape_y values in `networkx_nodes`. \n",
    "# Use that to get node_id from networkx_edges in the database,\n",
    "# Then use those id values to get edges info\n",
    "# Then line up the new integer labels with this list of ids to get betweeness centrality for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the betweeness_centrality values as the framework to join in shape_x, shape_y, and node_id\n",
    "bc_df_road = pd.DataFrame.from_dict(betweenness_dict_road, orient = 'index')\n",
    "bc_df_road = bc_df_road.rename(columns = {0: 'BC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_shape_df_road = pd.DataFrame(road_orig_label_nodes)\n",
    "\n",
    "bc_shape_df_road = pd.concat([bc_df_road, node_shape_df_road], axis = 1)\n",
    "bc_shape_df_road = bc_shape_df_road.rename(columns = {0: 'shape_x', 1: 'shape_y'})\n",
    "\n",
    "# Now add node_id from networkx_nodes, using pandas merge with left join.\n",
    "# Use both shape_x and shape_y to identify the nodes correctly\n",
    "# Union of both prod and crude now\n",
    "\n",
    "bc_node_df = pd.merge(bc_shape_df_road, nx_nodes, on = ['shape_x', 'shape_y'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this data frame to populate a data frame of edges. \n",
    "# We will want the following from networkx_edges:\n",
    "# edge_id, from_node_id, to_node_id, mode_source, miles, mode_source_oid, \n",
    "# Then using the node_id column in the new bc_node_df, add these:\n",
    "# from_node_BC, to_node_BC\n",
    "# and sum those for sum_node_BC\n",
    "merge_from = pd.merge(nx_edges, bc_node_df[['BC','node_id']],\n",
    "                      left_on = 'from_node_id',\n",
    "                      right_on = 'node_id',\n",
    "                      how = 'left')\n",
    "merge_from = merge_from.rename(columns = {'BC': 'from_node_BC'})\n",
    "\n",
    "merge_to = pd.merge(merge_from, bc_node_df[['BC','node_id',]],\n",
    "                    left_on = 'to_node_id',\n",
    "                    right_on = 'node_id',\n",
    "                    how = 'left')\n",
    "merge_to = merge_to.rename(columns = {'BC': 'to_node_BC'})\n",
    "\n",
    "# Sum the BC values\n",
    "\n",
    "merge_to['sum_BC'] = merge_to.filter(like = \"node_BC\").sum(axis = 1)\n",
    "\n",
    "# Then from optimal_variables, get variable_name, nc_edge_id, mode, mode_oid, miles,\n",
    "# variable_value, converted_capacity, and converted_volume\n",
    "\n",
    "use_opt_vars = ['variable_type',\n",
    "               'var_id',\n",
    "               'variable_value',\n",
    "                'variable_name',\n",
    "                'nx_edge_id',\n",
    "                'mode_oid',\n",
    "                'converted_capacity',\n",
    "                'converted_volume'\n",
    "               ]\n",
    "\n",
    "merge_opt = pd.merge(merge_to, optimal_vars[use_opt_vars],\n",
    "                    left_on = 'edge_id',\n",
    "                    right_on = 'nx_edge_id',\n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>artificial</th>\n",
       "      <th>mode_source</th>\n",
       "      <th>mode_source_oid</th>\n",
       "      <th>miles</th>\n",
       "      <th>route_cost_scaling</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>node_id_y</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>var_id</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17378</td>\n",
       "      <td>2</td>\n",
       "      <td>pipeline_prod_trf_rts</td>\n",
       "      <td>3642</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>rail</td>\n",
       "      <td>15397</td>\n",
       "      <td>0.090661</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9614</td>\n",
       "      <td>0</td>\n",
       "      <td>rail</td>\n",
       "      <td>1054</td>\n",
       "      <td>0.148076</td>\n",
       "      <td>2.1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  from_node_id  to_node_id  artificial            mode_source  \\\n",
       "0        1             0       17378           2  pipeline_prod_trf_rts   \n",
       "1        2             1        2555           0                   rail   \n",
       "2        3             1        9614           0                   rail   \n",
       "\n",
       "   mode_source_oid     miles  route_cost_scaling  capacity  volume  ...  \\\n",
       "0             3642  0.008758                 1.0       NaN     NaN  ...   \n",
       "1            15397  0.090661                 1.6    1050.0     0.0  ...   \n",
       "2             1054  0.148076                 2.1     600.0     0.0  ...   \n",
       "\n",
       "   node_id_y  sum_BC  variable_type  var_id  variable_value  variable_name  \\\n",
       "0        NaN     0.0            NaN     NaN             NaN            NaN   \n",
       "1        NaN     0.0            NaN     NaN             NaN            NaN   \n",
       "2        NaN     0.0            NaN     NaN             NaN            NaN   \n",
       "\n",
       "  nx_edge_id  mode_oid  converted_capacity converted_volume  \n",
       "0        NaN       NaN                 NaN              NaN  \n",
       "1        NaN       NaN                 NaN              NaN  \n",
       "2        NaN       NaN                 NaN              NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_opt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>miles</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65011</td>\n",
       "      <td>65012</td>\n",
       "      <td>26325</td>\n",
       "      <td>16624</td>\n",
       "      <td>2.391027</td>\n",
       "      <td>45396.405255</td>\n",
       "      <td>44631.0</td>\n",
       "      <td>5276624.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_173008</td>\n",
       "      <td>65012.0</td>\n",
       "      <td>12925.0</td>\n",
       "      <td>1.089514e+06</td>\n",
       "      <td>1071144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57386</td>\n",
       "      <td>57387</td>\n",
       "      <td>23196</td>\n",
       "      <td>183</td>\n",
       "      <td>3.527136</td>\n",
       "      <td>52814.692258</td>\n",
       "      <td>52543.0</td>\n",
       "      <td>4671108.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_152421</td>\n",
       "      <td>57387.0</td>\n",
       "      <td>12949.0</td>\n",
       "      <td>1.267553e+06</td>\n",
       "      <td>1261032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41214</td>\n",
       "      <td>41215</td>\n",
       "      <td>16624</td>\n",
       "      <td>7854</td>\n",
       "      <td>1.124715</td>\n",
       "      <td>50570.979389</td>\n",
       "      <td>46904.0</td>\n",
       "      <td>4404746.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_109126</td>\n",
       "      <td>41215.0</td>\n",
       "      <td>12525.0</td>\n",
       "      <td>1.213704e+06</td>\n",
       "      <td>1125696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  edge_id  from_node_id  to_node_id     miles      capacity   volume  \\\n",
       "0  65011    65012         26325       16624  2.391027  45396.405255  44631.0   \n",
       "1  57386    57387         23196         183  3.527136  52814.692258  52543.0   \n",
       "2  41214    41215         16624        7854  1.124715  50570.979389  46904.0   \n",
       "\n",
       "      sum_BC variable_type  variable_value variable_name  nx_edge_id  \\\n",
       "0  5276624.0          Edge       90.718474   Edge_173008     65012.0   \n",
       "1  4671108.0          Edge       90.718474   Edge_152421     57387.0   \n",
       "2  4404746.0          Edge       90.718474   Edge_109126     41215.0   \n",
       "\n",
       "   mode_oid  converted_capacity  converted_volume  \n",
       "0   12925.0        1.089514e+06         1071144.0  \n",
       "1   12949.0        1.267553e+06         1261032.0  \n",
       "2   12525.0        1.213704e+06         1125696.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ranked lists of edges to remove.\n",
    "# First, keep only edges in the optimal solution.\n",
    "# Then rank by sum_BC. Then just keep the columns we need, and reset the index.\n",
    "use_cols = ['edge_id', 'from_node_id', 'to_node_id', 'miles', 'capacity', 'volume', 'sum_BC',\n",
    "           'variable_type', 'variable_value', 'variable_name', 'nx_edge_id', 'mode_oid', 'converted_capacity', 'converted_volume']\n",
    "\n",
    "edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'sum_BC', ascending = False).filter(items = use_cols).reset_index()\n",
    "\n",
    "edges_remove.to_csv(os.path.join(scen_path, 'Edges_to_Remove.csv'),\n",
    "                   index = False)\n",
    "\n",
    "edges_remove.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scenarios, Disrupt, Run FTOT\n",
    "\n",
    "Create disrupted network by copying everyhing in `scen_path` to a new directory\n",
    "\n",
    "Then overwrites the `networkx_edges` tables in that main.db, with the disrupted versions.\n",
    "\n",
    "##### Assuptions:\n",
    "\n",
    "  1. ArcGIS with 64-bit geoprocessing is installed\n",
    "  2. The FTOT version being used has been modified according to the `README` in this directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 50 scenarios based on qs7_rmp_proc_dest_multi_inputs\n"
     ]
    }
   ],
   "source": [
    "disrupt_type = 'BC' # Can disrupt basaed on betweeness centrality or volume, 'V'\n",
    "disrupt_steps = 50  # This is the number of steps to use. Recommend at least 25.\n",
    "\n",
    "resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disrupted 50 scenarios\n"
     ]
    }
   ],
   "source": [
    "resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\program\\ftot.py\n"
     ]
    }
   ],
   "source": [
    "PYTHON = r\"c:\\PYTHON27\\ArcGISx6410.6\\python.exe\"\n",
    "repo_location = %pwd\n",
    "repo_location = os.path.split(repo_location)[0] \n",
    "FTOT = r\"C:\\FTOT\\program\\ftot.py\" # Optionally: os.path.join(repo_location, 'program', 'ftot.py')\n",
    "print(FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running o1 for disrupt01\n"
     ]
    }
   ],
   "source": [
    "# Begin running O steps of FTOT on the disupted scenarios\n",
    "# This may take several hours, depending on size of the network and number of steps\n",
    "\n",
    "results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Repeat with volume-based disruptions\n",
    "\n",
    "Creates a separate directory tree for the volume-based disruptions, and carries out the disruption steps on that set.\n",
    "\n",
    "Set the variable `DO_VOLUME` to `True` to run the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_VOLUME = False\n",
    "\n",
    "if DO_VOLUME:\n",
    "\n",
    "    disrupt_type = 'V'\n",
    "    disrupt_steps = 50\n",
    "\n",
    "    resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)\n",
    "    resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)\n",
    "    results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)\n",
    "    results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate disruption result report\n",
    "\n",
    "Run `compile_report.py`, which generates the `Disruption_Results.html` report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compile_report\n",
    "\n",
    "compile_report.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the report\n",
    "\n",
    "here = os.getcwd()\n",
    "\n",
    "webbrowser.open('file://' + os.path.realpath(os.path.join(here, 'Disruption_Results.html')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FTOTenv] *",
   "language": "python",
   "name": "conda-env-FTOTenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
